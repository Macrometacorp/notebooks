{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f63d4ffe",
   "metadata": {
    "kernelspec": {
     "display_name": "Javascript",
     "name": "javascript"
    }
   },
   "source": [
    "# JS09 - CI/CD Tutorial\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial we will build a simple CI/CD script for GDN plateform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da13fcd6-1552-42de-adc2-40adc794baa9",
   "metadata": {},
   "source": [
    "## Pre-requisite\n",
    "\n",
    "Lets Assume \n",
    "- you have already made a tenant account, and have a username and password\n",
    "- you have installed the jsc8 drivers as explained in section 01\n",
    "- you have generated an API Key as explained in section 01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b5920-c6c0-466c-b45f-742adfd14577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/* run this once to install javascript kernal and jsc8 in google colab, then reload, and then skip this\n",
    "!npm install jsc8\n",
    "!npm install -g --unsafe-perm ijavascript\n",
    "!ijsinstall --install=global  # */"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e4743f",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries & Define Variables\n",
    "\n",
    "The first step is to import the libraries we need and define the variables we will be using in this tutorial. This is also the right place to add your GDN login credentials. i.e. your email and password. You will also need to make sure you have specified the correct federation URL. In this example it is \"gdn.paas.macrometa.io\" and we are using the default geo fabric \"_system\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58664212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "const fed_url = \"https://gdn.pass.macrometa.io\";\n",
    "const email = \"email\"; // <-- Email goes here\n",
    "const password = \"password\"; // <-- password goes here\n",
    "const geo_fabric = \"_system\";\n",
    "\n",
    "const COLLECTION_TYPE = {\n",
    "  DOCUMENT: \"document\",\n",
    "  KV: \"graph\",\n",
    "};\n",
    "\n",
    "const fabricList = [\"cicd-fabric\"];\n",
    "\n",
    "const collectionList = [\n",
    "  {\n",
    "    name: \"Doc1\",\n",
    "    type: COLLECTION_TYPE.DOCUMENT,\n",
    "    isEdge: false,\n",
    "    hasStream: true,\n",
    "    noOfInsertOperation: 100,\n",
    "    noOfUpdateOperation: 1,\n",
    "    noOfDeleteOperations: 100,\n",
    "  },\n",
    "  {\n",
    "    name: \"Doc2\",\n",
    "    type: COLLECTION_TYPE.DOCUMENT,\n",
    "    isEdge: false,\n",
    "    hasStream: true,\n",
    "    noOfInsertOperation: 100,\n",
    "    noOfUpdateOperation: 1,\n",
    "    noOfDeleteOperations: 100,\n",
    "  },\n",
    "  { name: \"KV1\", type: COLLECTION_TYPE.KV, hasStream: true },\n",
    "];\n",
    "\n",
    "const streamList = [\n",
    "  {\n",
    "    name: \"gstream\",\n",
    "    isLocal: false,\n",
    "    noOfInsertOperation: 10,\n",
    "    noOfUpdateOperation: 0,\n",
    "    noOfDeleteOperations: 0,\n",
    "  },\n",
    "  {\n",
    "    name: \"lstream\",\n",
    "    isLocal: true,\n",
    "    noOfInsertOperation: 10,\n",
    "    noOfUpdateOperation: 0,\n",
    "    noOfDeleteOperations: 0,\n",
    "  },\n",
    "];\n",
    "\n",
    "const restqlList = {\n",
    "  insert_data: {\n",
    "    name: \"insertRecord\",\n",
    "    value: `FOR i IN 1..100 \n",
    "                INSERT {\n",
    "                    \"firstname\":CONCAT(\"Halie\", TO_STRING(i)),\n",
    "                    \"lastname\":CONCAT(\"Linkie\", TO_STRING(i)),\n",
    "                    \"email\":CONCAT(\"hlinkie0\", TO_STRING(i),\"@irs.gov\"),\n",
    "                    \"zipcode\": CONCAT(\"2950-53\", TO_STRING(i))\n",
    "                } INTO COLLECTION_NAME`,\n",
    "    parameter: {},\n",
    "  },\n",
    "  get_data: {\n",
    "    name: \"getRecords\",\n",
    "    value: `FOR doc IN COLLECTION_NAME RETURN doc`,\n",
    "  },\n",
    "  update_data: {\n",
    "    name: \"updateRecord\",\n",
    "    value: `FOR doc IN COLLECTION_NAME \n",
    "      filter doc.email == 'hlinkie05@irs.gov'\n",
    "      UPDATE { _key:doc._key,  \\\"lastname\\\": \\\"cena\\\" }\n",
    "        IN COLLECTION_NAME`,\n",
    "  },\n",
    "  get_count: {\n",
    "    name: \"countRecords\",\n",
    "    value: `RETURN COUNT(FOR doc IN COLLECTION_NAME RETURN 1)`,\n",
    "  },\n",
    "  delete_data: {\n",
    "    name: \"deleteRecord\",\n",
    "    value: `FOR doc IN COLLECTION_NAME \n",
    "          filter doc.email == 'hlinkie03@irs.gov'\n",
    "          REMOVE doc \n",
    "          IN COLLECTION_NAME `,\n",
    "  },\n",
    "  delete_all_data: {\n",
    "    name: \"deleteAllRecord\",\n",
    "    value: `FOR doc IN COLLECTION_NAME\n",
    "        REMOVE doc \n",
    "        IN COLLECTION_NAME `,\n",
    "  },\n",
    "};\n",
    "\n",
    "const graphList = [\n",
    "  {\n",
    "    name: \"social\",\n",
    "    edgeDefinitions: [\n",
    "      {\n",
    "        collection: \"relation\",\n",
    "        from: [\"female\", \"male\"],\n",
    "        to: [\"female\", \"male\"],\n",
    "      },\n",
    "    ],\n",
    "  },\n",
    "  { name: \"children\" },\n",
    "];\n",
    "\n",
    "const streamWorkerList = [\n",
    "  {\n",
    "    name: \"MockHeartRateDataGenerator\",\n",
    "    definition: `\n",
    "    @App:name(\"MockHeartRateDataGenerator\")\n",
    "    @App:qlVersion(\"2\")\n",
    "\n",
    "    CREATE TRIGGER HeartRateDataGeneratorTrigger WITH ( interval = 10 sec );\n",
    "\n",
    "    CREATE TABLE HeartRates (name string, bpm int);\n",
    "\n",
    "\n",
    "    -- Note: Generating random bpm and name \n",
    "    @info(name = 'ConsumeProcessedData')\n",
    "    INSERT INTO HeartRates\n",
    "    SELECT \n",
    "    js:eval(\"['Vasili', 'Rivalee', 'Betty', 'Jennifer', 'Alane', 'Sarena', 'Bruno', 'Carolee', 'Emmott', 'Andre'][Math.floor(Math.random() * 10)]\",\"string\") as name,\n",
    "    js:eval(\"Math.floor(Math.random() * 40) + 40\",\"int\") as bpm\n",
    "    FROM HeartRateDataGeneratorTrigger;\n",
    "    `,\n",
    "  },\n",
    "];\n",
    "\n",
    "const webSocketData = {};\n",
    "\n",
    "const webSocketList = [];\n",
    "\n",
    "let currentFabric = \"\";\n",
    "\n",
    "const DOCUMENT_OPERATIONS = {\n",
    "  UPDATE: \"UPDATE\",\n",
    "  INSERT: \"INSERT\",\n",
    "  DELETE: \"DELETE\",\n",
    "};\n",
    "\n",
    "const info = {\n",
    "  noOfCollection: 0,\n",
    "  noOfStreamWorker: 0,\n",
    "  noOfQueryWorker: 0,\n",
    "  noOfStream: 0,\n",
    "  noOfFabric: 0,\n",
    "  noOfGraph: 0,\n",
    "};\n",
    "\n",
    "let executeCiCDPipeLine;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba931134",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Connecting to GDN\n",
    "\n",
    "Now that we have imported the required libraries and added our login details, we can connect to GDN. Do this by running the cell bellow.\n",
    "\n",
    "You will see the cell output reflect a successful connection. If not go back to the first step and check the details you entered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c4fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "const jsc8 = require(\"jsc8\");\n",
    "\n",
    "// ----- simple way  -----\n",
    "const client = new jsc8(fed_url);\n",
    "\n",
    "client.useFabric(geo_fabric);\n",
    "client\n",
    "  .login(email, password)\n",
    "  .then((result) => console.log(\"Login successfully\", result))\n",
    "  .catch((err) => console.error(\"Error while login\", err.message));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20f00af",
   "metadata": {},
   "source": [
    "## 3. Creating Helper Functions\n",
    "\n",
    "Helper functions are basic building blocks for the CI/CD pipeline. These functions are responsible for creating/deleting collection, streams, query worker, stream worker, etc. based on the list provied in the section 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2376438c",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "// Logger function\n",
    "const log = (message) => {\n",
    "  console.info(`[${new Date()}]: ${message}`);\n",
    "};\n",
    "\n",
    "// Generate the random numbers\n",
    "const getRandomNumber = (min, max) => {\n",
    "  return Math.floor(Math.random() * (max - min + 1)) + min;\n",
    "};\n",
    "\n",
    "// Create the document collection\n",
    "const createDocumentCollection = async (\n",
    "  collectionName,\n",
    "  hasStream = true,\n",
    "  isEdge = false\n",
    ") => {\n",
    "  const hasCollection = await client.hasCollection(collectionName);\n",
    "  if (hasCollection) return;\n",
    "  await client.createCollection(collectionName, { stream: hasStream }, isEdge);\n",
    "  info.noOfCollection += 1;\n",
    "};\n",
    "\n",
    "// Create the kv collection\n",
    "const createKvCollection = async (collectionName, hasStream = true) => {\n",
    "  const hasCollection = await client.hasCollection(collectionName);\n",
    "  if (hasCollection) return;\n",
    "  await client.createKVCollection(collectionName, { stream: hasStream });\n",
    "  info.noOfCollection += 1;\n",
    "};\n",
    "\n",
    "// Create the query workers\n",
    "const createRestQL = async (resetql, restqlList) => {\n",
    "  try {\n",
    "    for (const collection of collectionList) {\n",
    "      const queryWorkerName = `${collection.name}_${resetql.name.toString()}`;\n",
    "      if (\n",
    "        collection.type != COLLECTION_TYPE.DOCUMENT ||\n",
    "        restqlList.includes(queryWorkerName)\n",
    "      )\n",
    "        continue;\n",
    "      await client.createRestql(\n",
    "        queryWorkerName,\n",
    "        resetql.value.toString().replaceAll(\"COLLECTION_NAME\", collection.name),\n",
    "        resetql.parameter\n",
    "      );\n",
    "    }\n",
    "  } catch (error) {\n",
    "    error.message =\n",
    "      `Error while creating restql ${resetql.name} : -- ` + error.message;\n",
    "    throw error;\n",
    "  }\n",
    "};\n",
    "\n",
    "// Create the GeoFabric\n",
    "const createFabric = async (fabricName, fabricList, localDcName, allDcList) => {\n",
    "  let globalDcList = [\n",
    "    allDcList[getRandomNumber(0, allDcList.length - 1)],\n",
    "    allDcList[getRandomNumber(0, allDcList.length - 1)],\n",
    "  ].filter((dataCenter) => dataCenter);\n",
    "  const dcList = [...new Set([...globalDcList, localDcName])];\n",
    "  if (fabricList.includes(fabricName)) return;\n",
    "  await client.createFabric(fabricName, [], {\n",
    "    dcList: dcList,\n",
    "  });\n",
    "  info.noOfFabric += 1;\n",
    "};\n",
    "\n",
    "// Create the graph\n",
    "const crateGraph = async (graphName, graphDetails = null) => {\n",
    "  const hasGraph = await client.hasGraph(graphName);\n",
    "  if (hasGraph) return;\n",
    "  await client.createGraph(graphName, graphDetails);\n",
    "  info.noOfGraph += 1;\n",
    "};\n",
    "\n",
    "// Create the stream\n",
    "const createStream = async (streamName, isLocal) => {\n",
    "  const isStreamExist = await client.hasStream(streamName, isLocal);\n",
    "  if (isStreamExist) return;\n",
    "  await client.createStream(streamName, isLocal);\n",
    "  info.noOfStream += 1;\n",
    "};\n",
    "\n",
    "// Create the stream subscriber\n",
    "const createSubscriber = async (\n",
    "  streamName,\n",
    "  isCollection = true,\n",
    "  isLocal = true\n",
    ") => {\n",
    "  try {\n",
    "    const wsConnection = await client.createStreamReader(\n",
    "      streamName,\n",
    "      streamName,\n",
    "      isLocal,\n",
    "      isCollection,\n",
    "      client._connection._urls[0].replace(\"https://api-\", \"\")\n",
    "    );\n",
    "    // await client.deleteStreamSubscription(streamName, streamName, isLocal, isCollection);\n",
    "\n",
    "    wsConnection.on(\"open\", () => {\n",
    "      log(`Connection open for ${streamName}`);\n",
    "      webSocketData[streamName] = {};\n",
    "      webSocketData[streamName][DOCUMENT_OPERATIONS.UPDATE] = [];\n",
    "      webSocketData[streamName][DOCUMENT_OPERATIONS.INSERT] = [];\n",
    "      webSocketData[streamName][DOCUMENT_OPERATIONS.DELETE] = [];\n",
    "    });\n",
    "    wsConnection.on(\"close\", () => log(`Connection close for ${streamName}`));\n",
    "    wsConnection.on(\"error\", (error) => log(error));\n",
    "\n",
    "    wsConnection.on(\"message\", (event) => {\n",
    "      const encodedMessage = JSON.parse(event).payload;\n",
    "      let data = {};\n",
    "      const decodedMessage = atob(encodedMessage);\n",
    "\n",
    "      if (decodedMessage.length !== 0) {\n",
    "        data = JSON.parse(decodedMessage);\n",
    "      }\n",
    "      const oldDocumentData = webSocketData[streamName];\n",
    "      switch (JSON.parse(event).properties.op) {\n",
    "        case DOCUMENT_OPERATIONS.UPDATE:\n",
    "          oldDocumentData[DOCUMENT_OPERATIONS.UPDATE].push(data);\n",
    "          break;\n",
    "        case DOCUMENT_OPERATIONS.DELETE:\n",
    "          oldDocumentData[DOCUMENT_OPERATIONS.DELETE].push(data);\n",
    "          break;\n",
    "        default:\n",
    "          oldDocumentData[DOCUMENT_OPERATIONS.INSERT].push(data);\n",
    "      }\n",
    "      wsConnection.send(\n",
    "        JSON.stringify({ messageId: JSON.parse(event).messageId })\n",
    "      );\n",
    "    });\n",
    "    webSocketList.push(wsConnection);\n",
    "  } catch (error) {\n",
    "    error.message =\n",
    "      `Error while creating subscriber ${streamName} : -- ` + error.message;\n",
    "    throw error;\n",
    "  }\n",
    "};\n",
    "\n",
    "// Create the stream publisher\n",
    "const createPublisher = async (streamName, isLocal, isCollection) => {\n",
    "  const producer = await client.createStreamProducer(\n",
    "    streamName,\n",
    "    isLocal,\n",
    "    isCollection\n",
    "  );\n",
    "  producer.on(\"open\", () => {\n",
    "    // If you message is an object, convert the obj to string.\n",
    "    // e.g. const message = JSON.stringify({message:'Hello World'});\n",
    "    for (let i = 0; i < 10; i++) {\n",
    "      const message = {\n",
    "        firstname: `Halie${i}`,\n",
    "        lastname: `Linkie${i}`,\n",
    "        email: `hlinkie0${i}@irs.gov`,\n",
    "        zipcode: `2950-53${i}`,\n",
    "      };\n",
    "      const payloadObj = {\n",
    "        payload: Buffer.from(JSON.stringify(message)).toString(\"base64\"),\n",
    "      };\n",
    "      producer.send(JSON.stringify(payloadObj));\n",
    "    }\n",
    "  });\n",
    "};\n",
    "\n",
    "// Create the stream based on provided stream list in streamList\n",
    "const createStreams = async () => {\n",
    "  const promiseList = streamList.map((stream) =>\n",
    "    createStream(stream.name, stream.isLocal)\n",
    "  );\n",
    "\n",
    "  await Promise.all(promiseList);\n",
    "};\n",
    "\n",
    "// Create the stream subscribers based on provided stream list in streamList\n",
    "const createStreamSubscribers = async () => {\n",
    "  const promiseList = streamList.map((stream) =>\n",
    "    createSubscriber(stream.name, false, stream.isLocal)\n",
    "  );\n",
    "  await Promise.all(promiseList);\n",
    "};\n",
    "\n",
    "// Create the stream publisher based on provided stream list in streamList\n",
    "const createStreamPublisher = async () => {\n",
    "  const promiseList = streamList.map((stream) =>\n",
    "    createPublisher(stream.name, stream.isLocal, false)\n",
    "  );\n",
    "  await Promise.all(promiseList);\n",
    "};\n",
    "\n",
    "// Create the new fabric\n",
    "const createNewFabrics = async () => {\n",
    "  const localDc = await client.getLocalDc();\n",
    "  const localDcName = localDc[\"_key\"];\n",
    "  const [allDcList] = await client.getDcList();\n",
    "  let globalDcList = allDcList.dcInfo\n",
    "    .map((dc) => dc._key)\n",
    "    .filter((dcName) => dcName != localDcName);\n",
    "  const existingFabricList = await client.listFabrics();\n",
    "\n",
    "  const promiseList = fabricList.map((fabric) =>\n",
    "    createFabric(fabric, existingFabricList, localDcName, globalDcList)\n",
    "  );\n",
    "  await Promise.all(promiseList);\n",
    "\n",
    "  currentFabric = fabricList[getRandomNumber(0, fabricList.length - 1)];\n",
    "  client.useFabric(currentFabric);\n",
    "};\n",
    "\n",
    "// Create the collections based on provided collection list in collectionList\n",
    "const createCollections = async () => {\n",
    "  const promiseList = collectionList.map((collection) => {\n",
    "    let func = createDocumentCollection;\n",
    "    if (collection.type === COLLECTION_TYPE.KV) func = createKvCollection;\n",
    "    return func(collection.name, collection.hasStream, collection.isEdge);\n",
    "  });\n",
    "\n",
    "  await Promise.all(promiseList);\n",
    "};\n",
    "\n",
    "// Create the query workers based on provided query worker list in restqlList\n",
    "const createRestQLs = async () => {\n",
    "  for (const restqlKey of Object.keys(restqlList)) {\n",
    "    let existingRestqlList = await client.getRestqls();\n",
    "    existingRestqlList = existingRestqlList.result.map((restql) => restql.name);\n",
    "    await createRestQL(restqlList[restqlKey], existingRestqlList);\n",
    "    info.noOfQueryWorker += 1;\n",
    "  }\n",
    "};\n",
    "\n",
    "// Create the subscriber based on provided collection list in collectionList\n",
    "const createCollectionsSubscribers = async () => {\n",
    "  const promiseList = collectionList\n",
    "    .filter((collection) => collection.type === COLLECTION_TYPE.DOCUMENT)\n",
    "    .map((collection) => createSubscriber(collection.name));\n",
    "  await Promise.all(promiseList);\n",
    "};\n",
    "\n",
    "// Create the graphs based on provided graph list in graphList\n",
    "const createGraphs = async () => {\n",
    "  const promiseList = graphList.map((graph) =>\n",
    "    crateGraph(graph.name, { edgeDefinitions: graph.edgeDefinitions })\n",
    "  );\n",
    "\n",
    "  await Promise.all(promiseList);\n",
    "};\n",
    "\n",
    "// Create the stream worker based on provided stream list in streamAppList\n",
    "const createStreamWorkers = async () => {\n",
    "  const promiseList = [];\n",
    "  let streamAppList = await client.retrieveStreamApp();\n",
    "  streamAppList = streamAppList.streamApps.map((streamApp) => streamApp.name);\n",
    "  streamWorkerList.forEach((streamWorker) => {\n",
    "    if (!streamAppList.includes(streamWorker.name)) {\n",
    "      promiseList.push(\n",
    "        client\n",
    "          .createStreamApp([], streamWorker.definition)\n",
    "          .then((data) => (info.noOfStreamWorker += 1))\n",
    "      );\n",
    "    }\n",
    "  });\n",
    "  await Promise.all(promiseList);\n",
    "};\n",
    "\n",
    "// Activate the stream worker based on provided stream list in streamWorkerList\n",
    "const activateStreamWorkers = async (isActive = true) => {\n",
    "  const promiseList = [];\n",
    "  streamWorkerList.forEach((streamWorker) => {\n",
    "    promiseList.push(client.activateStreamApp(streamWorker.name, isActive));\n",
    "  });\n",
    "  await Promise.all(promiseList);\n",
    "};\n",
    "\n",
    "// set current fabric to jsc8 client\n",
    "const useFabric = () => {\n",
    "  client.useFabric(currentFabric);\n",
    "\n",
    "  log(`Using fabric ${currentFabric}`);\n",
    "};\n",
    "\n",
    "/*\n",
    "Execute all the query workers provided in the restqlList \n",
    "for every document collection present in collectionList \n",
    "*/\n",
    "const executeRestQLs = async () => {\n",
    "  for (const restql of Object.keys(restqlList)) {\n",
    "    for (const collection of collectionList) {\n",
    "      if (collection.type === COLLECTION_TYPE.DOCUMENT) {\n",
    "        await client.executeRestql(\n",
    "          `${collection.name}_${restqlList[restql].name.toString()}`,\n",
    "          restqlList[restql].data\n",
    "        );\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "};\n",
    "\n",
    "// Read the websocket data and verify the number of operations\n",
    "const verifyStreams = async () => {\n",
    "  // wait for 5 seconds to receive all the stream data\n",
    "  await new Promise((resolve) => setTimeout(resolve, 5000));\n",
    "  streamList.forEach((stream) => {\n",
    "    const wsData = webSocketData[stream.name];\n",
    "    if (\n",
    "      !(\n",
    "        wsData[DOCUMENT_OPERATIONS.INSERT].length ===\n",
    "          stream.noOfInsertOperation &&\n",
    "        wsData[DOCUMENT_OPERATIONS.UPDATE].length ===\n",
    "          stream.noOfUpdateOperation &&\n",
    "        wsData[DOCUMENT_OPERATIONS.DELETE].length ===\n",
    "          stream.noOfDeleteOperations\n",
    "      )\n",
    "    )\n",
    "      throw Error(`Websocket data validation failed for ${stream.name}`);\n",
    "  });\n",
    "};\n",
    "\n",
    "// Validate the collection stream websocket data and operations\n",
    "const verifyCollectionStream = async () => {\n",
    "  // wait for 5 seconds to receive all the stream data\n",
    "  await new Promise((resolve) => setTimeout(resolve, 5000));\n",
    "  collectionList\n",
    "    .filter((collection) => collection.type === COLLECTION_TYPE.DOCUMENT)\n",
    "    .forEach((collection) => {\n",
    "      const wsData = webSocketData[collection.name];\n",
    "      if (\n",
    "        !(\n",
    "          wsData[DOCUMENT_OPERATIONS.INSERT].length ===\n",
    "            collection.noOfInsertOperation &&\n",
    "          wsData[DOCUMENT_OPERATIONS.UPDATE].length ===\n",
    "            collection.noOfUpdateOperation &&\n",
    "          wsData[DOCUMENT_OPERATIONS.DELETE].length ===\n",
    "            collection.noOfDeleteOperations\n",
    "        )\n",
    "      )\n",
    "        throw Error(\n",
    "          `Websocket data validation failed for collection ${collection.name}`\n",
    "        );\n",
    "    });\n",
    "};\n",
    "\n",
    "// Delete all the query workers present in the fabric\n",
    "const deleteRestQLs = async () => {\n",
    "  const promiseList = [];\n",
    "  const restqlList = await client.listSavedQueries();\n",
    "  restqlList.result.forEach((query) => client.deleteRestql(query.name));\n",
    "\n",
    "  await Promise.all(promiseList);\n",
    "};\n",
    "\n",
    "// Delete all the graphs present in the fabric\n",
    "const deleteGraphs = async () => {\n",
    "  const graphList = await client.listGraphs();\n",
    "  const promiseList = graphList.map((graph) =>\n",
    "    client.deleteGraph(graph.name, true)\n",
    "  );\n",
    "  await Promise.all(promiseList);\n",
    "};\n",
    "\n",
    "// Delete all the collection present in the fabric\n",
    "const deleteCollections = async () => {\n",
    "  const collectionList = await client.listCollections();\n",
    "  const promiseList = collectionList.map((collection) =>\n",
    "    client.deleteCollection(collection.name)\n",
    "  );\n",
    "  await Promise.all(promiseList);\n",
    "};\n",
    "\n",
    "// Delete all the fabric workers present in the fabricList\n",
    "const deleteFabrics = async () => {\n",
    "  client.useFabric(\"_system\");\n",
    "  const promiseList = fabricList.map((fabricName) =>\n",
    "    client.dropFabric(fabricName)\n",
    "  );\n",
    "  await Promise.all(promiseList);\n",
    "};\n",
    "\n",
    "// Terminate all the websocket\n",
    "const clearWebsocket = async () => {\n",
    "  webSocketList.forEach((webSocket) => {\n",
    "    webSocket.terminate();\n",
    "  });\n",
    "};\n",
    "\n",
    "// Delete all the streams present in the fabric\n",
    "const deleteStreams = async () => {\n",
    "  const streamsList = await client.getStreams();\n",
    "  const promiseList = streamsList.result.map((stream) =>\n",
    "    client.stream(stream.topic).deleteStream()\n",
    "  );\n",
    "  await Promise.all(promiseList);\n",
    "};\n",
    "\n",
    "// Delete all the streams worker present in the fabric\n",
    "const deleteStreamWorker = async () => {\n",
    "  const allSteamApps = await client.getAllStreamApps();\n",
    "  const promiseList = allSteamApps.streamApps.map((streamApp) =>\n",
    "    client.deleteStreamApp(streamApp.name)\n",
    "  );\n",
    "  await Promise.all(promiseList);\n",
    "};\n",
    "\n",
    "// It will delete the query-workers, graphs, collections, streams, stream-workers and fabric\n",
    "const clear = async () => {\n",
    "  useFabric();\n",
    "  await deleteRestQLs();\n",
    "  await deleteGraphs();\n",
    "  await deleteCollections();\n",
    "  await deleteStreams();\n",
    "  await deleteStreamWorker();\n",
    "  await deleteFabrics();\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febace29-21e0-4d75-993a-198f546a5737",
   "metadata": {},
   "source": [
    "## 4. Create CI/CD Pipeline\n",
    "\n",
    "Below function contains the list of sub functions.Each subfunction is responsible for either creating or deleting the elements in the GDN. \n",
    "\n",
    "Current flow is as below \n",
    "- Create fabrics\n",
    "- Pick any random fabric from created fabric\n",
    "- Create collections\n",
    "- Create query worker for each collection \n",
    "- Create stream workers \n",
    "- Activate the stream workers\n",
    "- Create the collection subscribers\n",
    "- Execute the query workers\n",
    "- Execute the CRUD using import API and truncate the collection. This operation is operformed on each collection \n",
    "- Validate the collection streams after query worker and CRUD operation execution with expected output\n",
    "- Create streams\n",
    "- Create the stream subscribers\n",
    "- Create the stream publisher. Publisher is pushing some records in the streams\n",
    "- Verify the stream output by counting the number of object received in the stream.\n",
    "- Unpublish the stream worker\n",
    "- Delete all the queryworkers, all the graphs, all the collections, all the streams, all the stream workers, and delete the number of fabric we created in the starting of program\n",
    "\n",
    "\n",
    "If you want to customize the CI/CD pipeline then please comment the appropriate steps and modify the CI/CD pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f650d6f6-5ede-429f-abdb-c5938fab21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "// It will execute GDN pipeline in series manner\n",
    "const executeCiCDPipeLine = async () => {\n",
    "  \n",
    "  try {\n",
    "    log(\"\\n ------- CREATE FABRICS ------\");\n",
    "    await createNewFabrics();\n",
    "    log(\"\\n ------- CREATED FABRICS ------\");\n",
    "\n",
    "    useFabric();\n",
    "\n",
    "    log(\"\\n ------- CREATE GEO-REPLICATED COLLECTION  ------\");\n",
    "    await createCollections();\n",
    "    log(\"\\n ------- CREATED GEO-REPLICATED COLLECTION  ------\");\n",
    "\n",
    "    log(\"\\n ------- CREATE GRAPHS ------\");\n",
    "    await createGraphs();\n",
    "    log(\"\\n ------- CREATED GRAPHS  ------\");\n",
    "\n",
    "    log(\"\\n ------- CREATE RESTQLS  ------\");\n",
    "    await createRestQLs();\n",
    "    log(\"\\n ------- CREATED RESTQLS  ------\");\n",
    "\n",
    "    log(\"\\n ------- CREATE STREAM WORKERS  ------\");\n",
    "    await createStreamWorkers();\n",
    "    log(\"\\n ------- CREATED STREAM WORKERS  ------\");\n",
    "\n",
    "    log(\"\\n ------- PUBLISH STREAM WORKERS  ------\");\n",
    "    await activateStreamWorkers();\n",
    "    log(\"\\n ------- PUBLISH STREAM WORKERS  ------\");\n",
    "\n",
    "    log(\"\\n ------- CREATE COLLECTION SUBSCRIBER  ------\");\n",
    "    await createCollectionsSubscribers();\n",
    "    log(\"\\n ------- CREATED COLLECTION SUBSCRIBER  ------\");\n",
    "\n",
    "    log(\"\\n ------- EXECUTE CRUD USING RESETQL ------\");\n",
    "    await executeRestQLs();\n",
    "    log(\"\\n ------- EXECUTED CRUD USING RESETQL ------\");\n",
    "\n",
    "    log(\"\\n ------- VERIFY COLLECTION STREAM ------\");\n",
    "    await verifyCollectionStream();\n",
    "    log(\"\\n ------- VERIFIED COLLECTION STREAM ------\");\n",
    "\n",
    "    log(\"\\n ------- CREATE STREAM ------\");\n",
    "    await createStreams();\n",
    "    log(\"\\n ------- CREATED STREAM ------\");\n",
    "\n",
    "    log(\"\\n ------- SUBSCRIBE STREAM ------\");\n",
    "    await createStreamSubscribers();\n",
    "    log(\"\\n ------- SUBSCRIBED STREAM ------\");\n",
    "\n",
    "    log(\"\\n ------- CREATE STREAM PRODUCER ------\");\n",
    "    await createStreamPublisher();\n",
    "    log(\"\\n ------- CREATED STREAM PRODUCER ------\");\n",
    "\n",
    "    log(\"\\n ------- VERIFY STREAM ------\");\n",
    "    await verifyStreams();\n",
    "    log(\"\\n ------- VERIFY STREAM ------\");\n",
    "\n",
    "    log(\"\\n ------- UNPUBLISH STREAM WORKERS  ------\");\n",
    "    await activateStreamWorkers(false);\n",
    "    log(\"\\n ------- UNPUBLISH STREAM WORKERS  ------\");\n",
    "\n",
    "    // clearing everything from previous runs\n",
    "    log(\"\\n ------- CLEARING ------\");\n",
    "    await clear();\n",
    "    log(\"\\n ------- CLEARED  ------\");\n",
    "\n",
    "    log(`Info: ${JSON.stringify(info)}`);\n",
    "  } catch (error) {\n",
    "    console.log(error.message);\n",
    "  } finally {\n",
    "    clearWebsocket();\n",
    "  }\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04554fa",
   "metadata": {},
   "source": [
    "## 5. Execute CI/CD script\n",
    "\n",
    "Below function is executing the CI/CD pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a405ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Execute the CI/CD pipeline\n",
    "executeCiCDPipeLine();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba04413",
   "metadata": {},
   "source": [
    "## Section Completed!\n",
    "\n",
    "Congratulations! you have completed this tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JavaScript (Node.js)",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "17.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
