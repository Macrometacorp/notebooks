{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f63d4ffe",
   "metadata": {
    "kernelspec": {
     "display_name": "Javascript",
     "name": "javascript"
    }
   },
   "source": [
    "# Py08 - Stream Workers\n",
    "\n",
    "## Overview\n",
    "\n",
    "Macrometa GDN allows you to integrate streaming data and take appropriate actions. Most stream processing use cases involve collecting, analyzing, and integrating or acting on data generated during business activities by various sources.\n",
    "\n",
    "| Stage | Description | \n",
    "|  :----:  |    :----:   |\n",
    "| Collect | Receive or capture data from various data sources.| \n",
    "| Analyze | Analyze data to identify interesting patterns and extract information.| \n",
    "| Act | Take actions based on the findings. For example, running simple code, calling an external service, or triggering a complex integration.| \n",
    "| Integrate | Provide processed data for consumer consumption.| \n",
    "\n",
    "You can process streams to perform the following actions with your data:\n",
    "\n",
    "- Transform data from one format to another. For example, from XML to JSON.\n",
    "- Enrich data received from a specific source by combining it with databases and services.\n",
    "- Correlate data by joining multiple streams to create an aggregate stream.\n",
    "- Clean data by filtering it and by modifying the content in messages. For example, obfuscating sensitive information.\n",
    "- Derive insights by identifying event patterns in data streams.\n",
    "- Summarize data with time windows and incremental aggregations.\n",
    "- Real-time ETL for collections, tailing files, and scraping HTTP endpoints.\n",
    "- Integrating stream data and trigger actions based on the data. This can be a single service request or a complex enterprise integration flow.\n",
    "\n",
    "In this tutorial we will build a simple stream worker for finding various heart rate measures like average bpm, minimum bpm etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da13fcd6-1552-42de-adc2-40adc794baa9",
   "metadata": {},
   "source": [
    "## Pre-requisite\n",
    "\n",
    "Let's assume your \n",
    "\n",
    "- tenant name is an email address\n",
    "- user password is xxxxx.\n",
    "\n",
    "if you need to install pyc8, you can run the cell below, otherwise you may skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b5920-c6c0-466c-b45f-742adfd14577",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyC8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e4743f",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries & Define Variables\n",
    "\n",
    "The first step is to import the libraries we need and define the variables we will be using in this tutorial. This is also the right place to add your GDN login credentials. i.e. your email and password. You will also need to make sure you have specified the correct federation URL. In this example it is \"gdn.paas.macrometa.io\" and we are using the default geo fabric \"_system\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58664212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from c8 import C8Client\n",
    "\n",
    "# Variables - Queries\n",
    "fed_url = \"gdn.paas.macrometa.io\";\n",
    "email = \"email\"; # <-- Email goes here\n",
    "password = \"password\"; # <-- password goes here\n",
    "geo_fabric = \"_system\";\n",
    "heart_rates_collection = \"HeartRates\";\n",
    "heart_rates_statistics_collection = \"HeartRateStatistics\";\n",
    "\n",
    "heart_rate_statistics_worker = \"HeartRateStatisticsWorker\";\n",
    "mock_heart_rate_data_generator = \"MockHeartRateDataGenerator\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba931134",
   "metadata": {},
   "source": [
    "## 2. Connecting to GDN\n",
    "\n",
    "Now that we have imported the required libraries and added our login details, we can connect to GDN. Do this by running the cell bellow.\n",
    "\n",
    "You will see the cell output reflect a successful connection. If not go back to the first step and check the details you entered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c4fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the C8 Data Fabric client.\n",
    "print(\"\\n ------- CONNECTION SETUP  ------\")\n",
    "print(\"tenant: {}, geofabric:{}\".format(email, geo_fabric))\n",
    "client = C8Client(protocol='https', host=fed_url, port=443,\n",
    "                email=email, password=password,\n",
    "                geofabric=geo_fabric)  \n",
    "\n",
    "# For the \"mytenant\" tenant, connect to \"_system\" fabric as tenant admin.\n",
    "# This returns an API wrapper for the \"_system\" fabric on tenant 'mytenant'\n",
    "# Note that the 'mytenant' tenant should already exist.\n",
    "\n",
    "tenant = client.tenant(email=email, password=password)\n",
    "\n",
    "sys_fabric = tenant.useFabric('_system')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20f00af",
   "metadata": {},
   "source": [
    "## 3. Creating Collections\n",
    "\n",
    "For this Tutorial we require the creation of two collections. The first will be a collection for the heart rates, which will hold our input data. The second will be a collection for the stream worker output which will hold the statistics.\n",
    "\n",
    "Run the next cell to create these two collections. Note the If-Else statements that are included in this cell. This lets us check to see if the collections exist already in the federation you are using, if they dont exist we will create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2376438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new collection if it does not exist\n",
    "print(\"\\n 3. CREATE_COLLECTION\");\n",
    "if client.has_collection(heart_rates_collection):\n",
    "    print(\"Collection {} exists\".format(heart_rates_collection))\n",
    "else:\n",
    "    client.create_collection(name=heart_rates_collection)\n",
    "    print(\"Collection {} Created!\".format(heart_rates_collection))\n",
    "    \n",
    "if client.has_collection(heart_rates_statistics_collection):\n",
    "    print(\"Collection {} exists\".format(heart_rates_statistics_collection))\n",
    "else:\n",
    "    client.create_collection(name=heart_rates_statistics_collection)\n",
    "    print(\"Collection {} Created!\".format(heart_rates_statistics_collection))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580a9d10-827d-49a4-b4c4-19eac92e10ec",
   "metadata": {},
   "source": [
    "**Note: for this to work you need to enable the collection stream from the Macrometa Dashboard. Do this by opening up the dashboard, select collections, find the collection named \"HeartRates\" and select \\\"Enable Stream\\\"**\n",
    "\n",
    "![disabledstream](./../images/disabled_stream.png)\n",
    "\n",
    "![enabledstream](./../images/enabled_stream.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa91d22",
   "metadata": {},
   "source": [
    "## 4. Validate Stream Application\n",
    "\n",
    "Now that we have created our collections we need to decide how we want to simulate the heart rate information. in this section we offer two approaches for simulating this data. \n",
    "\n",
    "Option 1, is to use a 3rd party tool called \"Mockaroo\" that will let you generate the data stream as an external source to Macrometa GDN. This would be closest to a \"real world\" use case showing data coming into GDN (and our streamworker) from an external source.\n",
    "\n",
    "Option 2. demostrates how Macrometa GDN Stream Workers can also be used to provide simulation data, or indeed the streaming of data from a collection.\n",
    "\n",
    "The end result will be the same, however for simplicity please select one option or the other, not both.\n",
    "\n",
    "Select the option you are going to use, and run the code in the corresponding cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd461db7-d6b3-4f0a-824a-9f99909a46d5",
   "metadata": {},
   "source": [
    "### 4.1 Validating heart rate simulator definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9ef716-f3fb-4306-bc04-7bd8f3703f40",
   "metadata": {},
   "source": [
    "#### Option1: Use mockaroo api to generate the mock heart rate data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fb12e0-371c-43dd-bbc5-4e58d291cff1",
   "metadata": {},
   "source": [
    "NOTE: If you are using mockaroo API then you need to signup to mockaroo and paste the API Key. You can find API key here https://www.mockaroo.com/myaccount\n",
    "\n",
    "In this Stream Worker we have created a trigger that triggers every 10 seconds and connects to the Mockaroo API Service and passes the current time stamp to trigger the Mockaroo data generation. \n",
    "\n",
    "Then the Stream Worker consumes data received from the external Mockaroo service, selects the persons name and their heart rate and puts it into the collection \"HeartRates\".\n",
    "\n",
    "Stream Workers are written in JavaScript, the Cell bellow has two variables: one for yor Mackroo API Key, and the other \"dataGeneratorAppDefinition\", both are strings that are passed the Key and StreamWorker code, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c7c62e-a5b8-4988-b98b-735afbe83537",
   "metadata": {},
   "outputs": [],
   "source": [
    "mockarooAPIKey = \"XXXX\";\n",
    "dataGeneratorAppDefinition = '''\n",
    "@App:name('MockHeartRateDataGenerator')\n",
    "@App:description('Mock data generator by calling mockaroo api for heart rate')\n",
    "@App:qlVersion('2')\n",
    "\n",
    "\n",
    "CREATE TRIGGER HeartRateDataGeneratorTrigger WITH ( interval = 10 sec );\n",
    "\n",
    "CREATE TABLE HeartRates (name string, bpm int);\n",
    "\n",
    "CREATE SINK MockarooServiceCallSink WITH (type='http-call', sink.id='mockaroo-service', publisher.url='https://api.mockaroo.com/api/a6e130b0?count=10&key={}', map.type='json', method='GET') (triggered_time string);\n",
    "\n",
    "CREATE SOURCE MockarooServiceResponseSink WITH (type='http-call-response', sink.id='mockaroo-service', map.type='json', http.status.code='200') (name string, bpm int);\n",
    "\n",
    "\n",
    "INSERT INTO MockarooServiceCallSink\n",
    "SELECT time:currentTimestamp() as triggered_time \n",
    "FROM HeartRateDataGeneratorTrigger;\n",
    "\n",
    "-- Note: Consume data received from the external service\n",
    "@info(name = 'ConsumeProcessedData')\n",
    "INSERT INTO HeartRates\n",
    "SELECT name, bpm\n",
    "FROM MockarooServiceResponseSink;\n",
    "'''.format(mockarooAPIKey);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f552d33-6d0e-436b-9c26-22adeb7270be",
   "metadata": {},
   "source": [
    "#### Option2: Use custom stream worker to generate the heart rate data \n",
    "\n",
    "In this Stream Worker we have created a trigger that triggers every 10 seconds and creates random data from a short list of people and possible heart rates and puts it into the collection \"HeartRates\".\n",
    "\n",
    "Stream Workers are written in JavaScript, the Cell bellow has one variables, \"dataGeneratorAppDefinition\", it is a string type variable that is passed StreamWorker code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89296316-d102-4c31-9f25-c6d198181c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGeneratorAppDefinition = '''\n",
    "@App:name(\"MockHeartRateDataGenerator\")\n",
    "@App:qlVersion(\"2\")\n",
    "\n",
    "CREATE TRIGGER HeartRateDataGeneratorTrigger WITH ( interval = 10 sec );\n",
    "\n",
    "CREATE TABLE HeartRates (name string, bpm int);\n",
    "\n",
    "\n",
    "-- Note: Generating random bpm and name \n",
    "@info(name = 'ConsumeProcessedData')\n",
    "INSERT INTO HeartRates\n",
    "SELECT \n",
    "js:eval(\"['Vasili', 'Rivalee', 'Betty', 'Jennifer', 'Alane', 'Sarena', 'Bruno', 'Carolee', 'Emmott', 'Andre'][Math.floor(Math.random() * 10)]\",\"string\") as name,\n",
    "js:eval(\"Math.floor(Math.random() * 40) + 40\",\"int\") as bpm\n",
    "FROM HeartRateDataGeneratorTrigger;\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd11db4-4b83-4392-a2b6-e88d407de493",
   "metadata": {},
   "source": [
    "### 4.2 Validating stream worker\n",
    "\n",
    "Now that we have selected and run the cell code for our chosen method of generating data, we can move on to the next stream worker, and then validate them for correctness, before we publish them, and make them active.\n",
    "\n",
    "This next cell introduces the second stream worker that reads the heart rates from the collection \"HeartRates\" in a sliding window of 1 min, and then calculates the min, max and averages for that window, and inserts them into the collection \"HeartRateStatistics\". it is defined as a string and assigned to the \"statisticsAppDefinition\" variable.\n",
    "\n",
    "We then validate the streams by using the \"validate_stream_app\" method, as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf2fd75-4d40-4fa6-8d3c-d06e9a39a25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "statisticAppDefinition = '''\n",
    "@App:name('HeartRateStatisticsWorker')\n",
    "@App:description(\"Calculate the statistics for heart rates\")\n",
    "@App:qlVersion(\"2\")\n",
    "\n",
    "CREATE SOURCE HeartRates WITH (type = 'database', collection = \"HeartRates\", collection.type=\"doc\", replication.type=\"global\", map.type='json') (name string, bpm int);\n",
    "\n",
    "CREATE TABLE HeartRateStatistics (eventTime long, name string, minBpm int, maxBpm int, avgBpm double);\n",
    "\n",
    "\n",
    "INSERT INTO HeartRateStatistics\n",
    "SELECT \n",
    "    eventTimestamp() as eventTime,\n",
    "    name as name,\n",
    "    min(bpm) as minBpm,\n",
    "    max(bpm) as maxBpm,\n",
    "    avg(bpm) as avgBpm\n",
    "FROM HeartRates window sliding_time(1 min)\n",
    "group by name\n",
    "''';\n",
    "\n",
    "\n",
    "print(\"\\n 4. VALIDATE_STREAM_WORKERS ... region {}\".format(fed_url));\n",
    "\n",
    "print(\"--- Validating Stream Application Definition\");\n",
    "result = client.validate_stream_app(data=statisticAppDefinition);\n",
    "\n",
    "print(\"--- Validated HeartRateStatisticsWorker Stream Application Definition {} ---\".format(result));\n",
    "result = client.validate_stream_app(data = dataGeneratorAppDefinition);\n",
    "\n",
    "print(\"--- Validated MockHeartRateDataGenerator Stream Application Definition {} ---\".format(result));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febace29-21e0-4d75-993a-198f546a5737",
   "metadata": {},
   "source": [
    "## 5. Save Stream Application\n",
    "\n",
    "Upon a successful validation we can save our streamworkers by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f650d6f6-5ede-429f-abdb-c5938fab21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n 5. CREATE_STREAM_WORKERS ... region {}\".format(fed_url));\n",
    "print(\"--- Creating Stream Application\");\n",
    "#The stream app will be created by default in the local region. Optionally, you can send dclist to deploy stream\n",
    "result = client.create_stream_app(data=statisticAppDefinition);\n",
    "\n",
    "print(\"--- Created Stream Application {} ---\".format(heart_rate_statistics_worker));\n",
    "result = client.create_stream_app(data=dataGeneratorAppDefinition);\n",
    "\n",
    "print(\"--- Created Stream Application {} ---\".format(mock_heart_rate_data_generator));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fba0bdc-635b-4e12-b011-40923f3cdf1d",
   "metadata": {},
   "source": [
    "## 6. Publish Stream Application\n",
    "\n",
    "A saved stream worker does not mean it is active. For the Stream Worker to be active it needs to be Published. Run the code in the next cell to publish the stream worker and make it active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36473a8-89e9-49db-bade-e7a27306a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n6. Activating Stream Workers\");\n",
    "client.activate_stream_app(heart_rate_statistics_worker, True);\n",
    "client.activate_stream_app(mock_heart_rate_data_generator, True);\n",
    "print(\"6. Activated Stream Workers\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b7bde1-4bdd-47d2-9efb-78274a2e9b3e",
   "metadata": {},
   "source": [
    "## 7. Checking HeartRates documents using C8QL\n",
    "\n",
    "Now we have activated our stream workers the application is live. However, because we are using a 1 min window, we need to wait for 1 minute before we check for records being created.\n",
    "\n",
    "A good way to do this is that rather counting 60 seconds, is to load the GDN dashboard, select the \"HeartRate\" Collection, then \"stream\" and monitor the console. as soon as their are changes, you will see them reflected here.\n",
    "\n",
    "![monitoring_heart_rate](./../images/monitoring-HR-stream.png)\n",
    "\n",
    "Alternatively, wait 60 seconds, and run the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78aa21c-70e6-4d93-990e-80988767cd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please wait for 1 minute after executing above step as we used sliding window of 1 minute\n",
    "cursor = client.execute_query('FOR doc IN HeartRates LIMIT 0, 5 RETURN doc')\n",
    "\n",
    "docs = [document for document in cursor]\n",
    "\n",
    "print(json.dumps(docs, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842552ac",
   "metadata": {},
   "source": [
    "## 8. Checking HeartRateStatistics documents using C8QL\n",
    "\n",
    "Now that we have started to collect data in the HeartRates collection, we want to see our analysis. run the cell below to see the output from our stream worker!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4588e31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = client.execute_query('FOR doc IN HeartRateStatistics LIMIT 0, 5 RETURN doc')\n",
    "\n",
    "docs = [document for document in cursor]\n",
    "\n",
    "print(json.dumps(docs, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04554fa",
   "metadata": {},
   "source": [
    "## 9.  Delete StreamApp and Collections\n",
    "\n",
    "Almost done. Lets clean up after ourselves and remove the tutorial from GDN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a405ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n9. DELETE_DATA\");\n",
    "client.delete_stream_app(heart_rate_statistics_worker);\n",
    "client.delete_stream_app(mock_heart_rate_data_generator);\n",
    "client.delete_collection(heart_rates_collection);\n",
    "client.delete_collection(heart_rates_statistics_collection);\n",
    "print(\"StreamApp and Collection deleted\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba04413",
   "metadata": {},
   "source": [
    "## Section Completed!\n",
    "\n",
    "Congratulations! you have completed this tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
