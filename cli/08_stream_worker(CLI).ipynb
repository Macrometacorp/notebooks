{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f63d4ffe",
   "metadata": {
    "kernelspec": {
     "display_name": "Javascript",
     "name": "javascript"
    }
   },
   "source": [
    "# CLI08 - Stream Workers\n",
    "\n",
    "## Overview\n",
    "\n",
    "Macrometa GDN allows you to integrate streaming data and take appropriate actions. Most stream processing use cases involve collecting, analyzing, and integrating or acting on data generated during business activities by various sources.\n",
    "\n",
    "| Stage | Description | \n",
    "|  :----:  |    :----:   |\n",
    "| Collect | Receive or capture data from various data sources.| \n",
    "| Analyze | Analyze data to identify interesting patterns and extract information.| \n",
    "| Act | Take actions based on the findings. For example, running simple code, calling an external service, or triggering a complex integration.| \n",
    "| Integrate | Provide processed data for consumer consumption.| \n",
    "\n",
    "You can process streams to perform the following actions with your data:\n",
    "\n",
    "- Transform data from one format to another. For example, from XML to JSON.\n",
    "- Enrich data received from a specific source by combining it with databases and services.\n",
    "- Correlate data by joining multiple streams to create an aggregate stream.\n",
    "- Clean data by filtering it and by modifying the content in messages. For example, obfuscating sensitive information.\n",
    "- Derive insights by identifying event patterns in data streams.\n",
    "- Summarize data with time windows and incremental aggregations.\n",
    "- Real-time ETL for collections, tailing files, and scraping HTTP endpoints.\n",
    "- Integrating stream data and trigger actions based on the data. This can be a single service request or a complex enterprise integration flow.\n",
    "\n",
    "In this tutorial we will build a simple stream worker for finding various heart rate measures like average bpm, minimum bpm etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da13fcd6-1552-42de-adc2-40adc794baa9",
   "metadata": {},
   "source": [
    "## Pre-requisite\n",
    "\n",
    "Lets Assume \n",
    "- you have already made a tenant account, and have a username and password\n",
    "- you have installed the Macrometa CLI as explained in section 01\n",
    "- you have generated an API Key as explained in section 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b5920-c6c0-466c-b45f-742adfd14577",
   "metadata": {},
   "outputs": [],
   "source": [
    "npm install -g gdnsl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e4743f",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries & Define Variables\n",
    "\n",
    "The first step is to import the libraries we need and define the variables we will be using in this tutorial. This is also the right place to add your GDN login credentials. i.e. your email and password. You will also need to make sure you have specified the correct federation URL. In this example it is \"gdn.paas.macrometa.io\" and we are using the default geo fabric \"_system\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "58664212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables - Queries\n",
    "url=\"https://gdn.paas.macrometa.io\";\n",
    "apiKey=\"XXXX\"; # apiKey goes here if applicable\n",
    "email=\"email\"; # Email goes here\n",
    "# You can either use LOCAL or ALL also Please enter the name of the regions. For multiple regions enter comma-separated names. For example: region1, region2.\n",
    "regions=\"ALL\"\n",
    "heart_rates_collection=\"HeartRates\";\n",
    "heart_rates_statistics_collection=\"HeartRateStatistics\";\n",
    "heart_rate_statistics_worker=\"HeartRateStatisticsWorker\";\n",
    "mock_heart_rate_data_generator=\"MockHeartRateDataGenerator\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba931134",
   "metadata": {},
   "source": [
    "## 2. Connecting to GDN\n",
    "\n",
    "Now that we have imported the required libraries and added our login details, we can connect to GDN. do this by running the cell bellow.\n",
    "\n",
    "You will see the cell output reflect a successful connection. If not go back to the first step and check the details you entered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c4fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"Creating gdnsl.yaml file\" \n",
    "\n",
    "echo \"url: $url\n",
    "email: $email\n",
    "apikey: $apiKey\n",
    "regions:\n",
    "  - $regions\" > gdnsl.yaml\n",
    "\n",
    "echo \"------- CONNECTION SETUP  ------\"\n",
    "# if you are running this from terminal then you can ignore above step and run below command\n",
    "# gdnsl init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20f00af",
   "metadata": {},
   "source": [
    "## 3. Creating Collections\n",
    "\n",
    "For this Tutorial we require the creating of two collections. The first will be a collection for the heart rates, which will hold our input data. The second will be the collection for the stream worker output which will hold the statistics.\n",
    "\n",
    "Run the next cell to create these two collections. Note the If-Else statements that are included in this cell. This lets us check to see if the collections exist already in the federation you are using, if they dont exist we will create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2376438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \" ------- CREATE GEO-REPLICATED COLLECTION  ------\"\n",
    "gdnsl collection create $heart_rates_collection --type doc --stream \n",
    "echo \"Created collection: $heart_rates_collection\"\n",
    "gdnsl collection create $heart_rates_statistics_collection --type doc \n",
    "echo \"Created collection: $heart_rates_statistics_collection\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6584be-3fda-4ad9-ad2a-454b850cd5d2",
   "metadata": {},
   "source": [
    "**Note: for this to work you need to enable Stream from the Macrometa Dashboard. Do this by opening up the dashboard, select collections, find the collection named \"HeartRates\" and select \"enable Stream\"**\n",
    "\n",
    "![disabledstream](./../images/disabled_stream.png)\n",
    "\n",
    "![enabledstream](./../images/enabled_stream.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa91d22",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Validate Stream Application\n",
    "\n",
    "Now that we have created our collections we need to decide how we want to simulate the heart rate information. in this section we offer two approaches for simulating this data. \n",
    "\n",
    "Option 1, is to use a 3rd party tool called \"Mockaroo\" that will let you generate the data stream as an external source to Macrometa GDN. This would be closest to a \"real world\" use case showing data coming into GDN (and our streamworker) from an external source.\n",
    "\n",
    "Option 2. demostrates how Macrometa GDN Stream Workers can also be used to provide simulation data, or indeed the streaming of data from a collection.\n",
    "\n",
    "The end result will be the same, however for simplicity please select one option or the other, not both.\n",
    "\n",
    "Select the option you are going to use, and run the code in the corresponding cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd461db7-d6b3-4f0a-824a-9f99909a46d5",
   "metadata": {},
   "source": [
    "### 4.1 Validating heart rate simulator definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9ef716-f3fb-4306-bc04-7bd8f3703f40",
   "metadata": {},
   "source": [
    "#### Option1: Use mockaroo api to generate the mock heart rate data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fb12e0-371c-43dd-bbc5-4e58d291cff1",
   "metadata": {},
   "source": [
    "NOTE: If you are using mockaroo API then you need to signup to mockaroo and paste the API Key. You can find API key here https://www.mockaroo.com/myaccount\n",
    "\n",
    "In this Stream Worker we have created a trigger that triggers every 10 seconds and connects to the Mockaroo API Service and passes the current time stamp to trigger the Mockaroo data generation. \n",
    "\n",
    "Then the Stream Worker consumes data recived from the external Mockaroo service, selects the persons name and their heart rate and puts it into the collection \"HeartRates\".\n",
    "\n",
    "Stream Workers are written in JavaScript, the Cell bellow has two variables one for yor Mackroo API Key, and the other \"dataGeneratorAppDefinition\", both are strings that are passed the Key and StreamWorker code, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c7c62e-a5b8-4988-b98b-735afbe83537",
   "metadata": {},
   "outputs": [],
   "source": [
    "mockarooAPIKey=\"XXXX\";\n",
    "\n",
    "echo \"--- Validate $mock_heart_rate_data_generator Application\";\n",
    "\n",
    "gdnsl stream-worker create --name $mock_heart_rate_data_generator \\\n",
    "--description \"Mock data generator by calling mockaroo api for heart rate\" \\\n",
    "--trigger \"HeartRateDataGeneratorTrigger WITH ( interval = 10 sec );\" \\\n",
    "--table \"HeartRates (name string, bpm int);\" \\\n",
    "--sink \"MockarooServiceCallSink WITH (type='http-call', sink.id='mockaroo-service', publisher.url='https://api.mockaroo.com/api/a6e130b0?count=10&key=$mockarooAPIKey', map.type='json', method='GET') (triggered_time string);\" \\\n",
    "--source \"MockarooServiceResponseSink WITH (type='http-call-response', sink.id='mockaroo-service', map.type='json', http.status.code='200') (name string, bpm int);\" \\\n",
    "--query \"INSERT INTO MockarooServiceCallSink\n",
    "SELECT time:currentTimestamp() as triggered_time \n",
    "FROM HeartRateDataGeneratorTrigger;\" \\\n",
    "--query \"INSERT INTO HeartRates SELECT name, bpm FROM MockarooServiceResponseSink;\" \\\n",
    "--validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f552d33-6d0e-436b-9c26-22adeb7270be",
   "metadata": {},
   "source": [
    "#### Option2: Use custom stream worker to generate the heart rate data \n",
    "\n",
    "In this Stream Worker we have created a trigger that triggers every 10 seconds and creates random data from a short list of people and possible heart rates and puts it into the collection \"HeartRates\".\n",
    "\n",
    "Stream Workers are written in JavaScript, the Cell bellow has one variables, \"dataGeneratorAppDefinition\", it is a string type variable that is passed StreamWorker code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89296316-d102-4c31-9f25-c6d198181c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"--- Validate $mock_heart_rate_data_generator Application\";\n",
    "\n",
    "gdnsl stream-worker create --name $mock_heart_rate_data_generator \\\n",
    "--description \"Mock data generator by strem worker\" \\\n",
    "--trigger \"HeartRateDataGeneratorTrigger WITH ( interval = 10 sec );\" \\\n",
    "--table \"HeartRates (name string, bpm int);\" \\\n",
    "--query \"@info(name = 'ConsumeProcessedData')\n",
    "    INSERT INTO HeartRates\n",
    "    SELECT \n",
    "    js:eval(\\\"['Vasili', 'Rivalee', 'Betty', 'Jennifer', 'Alane', 'Sarena', 'Bruno', 'Carolee', 'Emmott', 'Andre'][Math.floor(Math.random() * 10)]\\\",\\\"string\\\") as name,\n",
    "    js:eval(\\\"Math.floor(Math.random() * 40) + 40\\\",\\\"int\\\") as bpm\n",
    "    FROM HeartRateDataGeneratorTrigger;\" \\\n",
    "--validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd11db4-4b83-4392-a2b6-e88d407de493",
   "metadata": {},
   "source": [
    "### 4.2 Validating stream worker\n",
    "\n",
    "Now that we have selected and run the cell code for our chosen menthod of generating data, we can move on to the next stream worker, and then validate them for correctness, before we publish them, and make them active.\n",
    "\n",
    "This next cell introduces the second stream worker that reads the heart rates from the collection \"HeartRates\" in a sliding window of 1 min, and then calculates the min max and averages for that window, and inserts them into the collection \"HeartRateStatistics\". it is defined as a string and assigned to the \"statisticsAppDefinition\" variable.\n",
    "\n",
    "We then validate the streams by using the \"validate_stream_app\" method, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf2fd75-4d40-4fa6-8d3c-d06e9a39a25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"--- Validate $heart_rate_statistics_worker Application\";\n",
    "  \n",
    "# The stream app will be created by default in the local region. Optionally, you can send dclist to deploy stream\n",
    "gdnsl stream-worker create --name $heart_rate_statistics_worker \\\n",
    "--description \"Calculate the statistics for heart rates\" \\\n",
    "--source \"HeartRates WITH (type = 'database', collection = 'HeartRates', collection.type='doc', replication.type='global', map.type='json') (name string, bpm int);\" \\\n",
    "--table \"HeartRateStatistics (eventTime long, name string, minBpm int, maxBpm int, avgBpm double);\" \\\n",
    "--query \"INSERT INTO HeartRateStatistics\n",
    "                SELECT \n",
    "                    eventTimestamp() as eventTime,\n",
    "                    name as name,\n",
    "                    min(bpm) as minBpm,\n",
    "                    max(bpm) as maxBpm,\n",
    "                    avg(bpm) as avgBpm\n",
    "                FROM HeartRates window sliding_time(1 min)\n",
    "                group by name\" \\\n",
    "--validate\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febace29-21e0-4d75-993a-198f546a5737",
   "metadata": {},
   "source": [
    "## 5. Save Stream Application\n",
    "\n",
    "Upon a successful validation we can save our streamworkers by running the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e32c7a-9f46-4020-a839-fd618fb55071",
   "metadata": {},
   "source": [
    "### 5.1 Creating heart rate simulator definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f02b2f-f0b0-46a3-9b5d-dc4229bf167c",
   "metadata": {},
   "source": [
    "#### Option1: Use mockaroo api to generate the mock heart rate data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1a1797-36dc-4829-ba39-737fa93be1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"--- Create $mock_heart_rate_data_generator Application\";\n",
    "\n",
    "gdnsl stream-worker create --name $mock_heart_rate_data_generator \\\n",
    "--description \"Mock data generator by calling mockaroo api for heart rate\" \\\n",
    "--trigger \"HeartRateDataGeneratorTrigger WITH ( interval = 10 sec );\" \\\n",
    "--table \"HeartRates (name string, bpm int);\" \\\n",
    "--sink \"MockarooServiceCallSink WITH (type='http-call', sink.id='mockaroo-service', publisher.url='https://api.mockaroo.com/api/a6e130b0?count=10&key=$mockarooAPIKey', map.type='json', method='GET') (triggered_time string);\" \\\n",
    "--source \"MockarooServiceResponseSink WITH (type='http-call-response', sink.id='mockaroo-service', map.type='json', http.status.code='200') (name string, bpm int);\" \\\n",
    "--query \"INSERT INTO MockarooServiceCallSink\n",
    "SELECT time:currentTimestamp() as triggered_time \n",
    "FROM HeartRateDataGeneratorTrigger;\" \\\n",
    "--query \"INSERT INTO HeartRates SELECT name, bpm FROM MockarooServiceResponseSink;\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b639c1f9-53d6-4cda-947a-a30c00f6f328",
   "metadata": {},
   "source": [
    "#### Option2: Use custom stream worker to generate the heart rate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30fb4e-9b23-4ba1-9c73-d25adf90b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"--- Validate $mock_heart_rate_data_generator Application\";\n",
    "\n",
    "gdnsl stream-worker create --name $mock_heart_rate_data_generator \\\n",
    "--description \"Mock data generator by strem worker\" \\\n",
    "--trigger \"HeartRateDataGeneratorTrigger WITH ( interval = 10 sec );\" \\\n",
    "--table \"HeartRates (name string, bpm int);\" \\\n",
    "--query \"@info(name = 'ConsumeProcessedData')\n",
    "    INSERT INTO HeartRates\n",
    "    SELECT \n",
    "    js:eval(\\\"['Vasili', 'Rivalee', 'Betty', 'Jennifer', 'Alane', 'Sarena', 'Bruno', 'Carolee', 'Emmott', 'Andre'][Math.floor(Math.random() * 10)]\\\",\\\"string\\\") as name,\n",
    "    js:eval(\\\"Math.floor(Math.random() * 40) + 40\\\",\\\"int\\\") as bpm\n",
    "    FROM HeartRateDataGeneratorTrigger;\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8158a3-74f8-4ed2-aa83-7957d58dd524",
   "metadata": {},
   "source": [
    "### 5.2 Creating heart rate statistics stream worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f650d6f6-5ede-429f-abdb-c5938fab21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"--- Create $heart_rate_statistics_worker Application\";\n",
    "  \n",
    "# The stream app will be created by default in the local region. Optionally, you can send dclist to deploy stream\n",
    "gdnsl stream-worker create --name $heart_rate_statistics_worker \\\n",
    "--description \"Calculate the statistics for heart rates\" \\\n",
    "--source \"HeartRates WITH (type = 'database', collection = 'HeartRates', collection.type='doc', replication.type='global', map.type='json') (name string, bpm int);\" \\\n",
    "--table \"HeartRateStatistics (eventTime long, name string, minBpm int, maxBpm int, avgBpm double);\" \\\n",
    "--query \"INSERT INTO HeartRateStatistics\n",
    "                SELECT \n",
    "                    eventTimestamp() as eventTime,\n",
    "                    name as name,\n",
    "                    min(bpm) as minBpm,\n",
    "                    max(bpm) as maxBpm,\n",
    "                    avg(bpm) as avgBpm\n",
    "                FROM HeartRates window sliding_time(1 min)\n",
    "                group by name\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fba0bdc-635b-4e12-b011-40923f3cdf1d",
   "metadata": {},
   "source": [
    "## 6. Publish Stream Application\n",
    "\n",
    "A saved stream worker does not mean it is active. For the Stream Worker to be active it needs to be Published. Run the code in the next cell to publish the strem worker and make it active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36473a8-89e9-49db-bade-e7a27306a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"Activating Stream Workers\"\n",
    "gdnsl stream-worker $heart_rate_statistics_worker --enable\n",
    "gdnsl stream-worker $mock_heart_rate_data_generator --enable\n",
    "echo \"Activated Stream Workers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b7bde1-4bdd-47d2-9efb-78274a2e9b3e",
   "metadata": {},
   "source": [
    "## 7. Checking HeartRates documents using C8QL\n",
    "\n",
    "Now we have activated our stream workers the application is live. However, because we are using a 1 min window, we need to wait that time before we check for records being created.\n",
    "\n",
    "A good way to do this rather than counting 60sec, is to load the GDN dashboard, select the \"HeartRate\" Collection, then \"stream\" and monitor the console. as soon as their are changes, you will see them reflected here.\n",
    "\n",
    "![monitoring_heart_rate](./../images/monitoring-HR-stream.png)\n",
    "\n",
    "Alternatively, wait 60 sec, and run the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78aa21c-70e6-4d93-990e-80988767cd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdnsl query \"FOR doc IN $heart_rates_collection LIMIT 0, 5 RETURN doc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842552ac",
   "metadata": {},
   "source": [
    "## 8. Checking HeartRateStatistics documents using C8QL\n",
    "\n",
    "Now that we have started to collect data in the heartrate collection, we want to see our analysis. run the cell below to see the output from our stream worker!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4588e31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdnsl query \"FOR doc IN $heart_rates_statistics_collection LIMIT 0, 5 RETURN doc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04554fa",
   "metadata": {},
   "source": [
    "## 9.  Delete StreamApp and Collections\n",
    "\n",
    "Almost done. Lets clean up after ourselves and remove the tutorial from GDN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a405ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \" DELETE_DATA\"\n",
    "gdnsl stream-worker delete $heart_rate_statistics_worker;\n",
    "gdnsl stream-worker delete $mock_heart_rate_data_generator;\n",
    "gdnsl collection delete $heart_rates_collection;\n",
    "gdnsl collection delete $heart_rates_statistics_collection;\n",
    "echo \"StreamApp and Collection deleted\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba04413",
   "metadata": {},
   "source": [
    "## Section Completed!\n",
    "\n",
    "Congratulations! you have completed this tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
